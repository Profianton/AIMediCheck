{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, concatenate\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = Input(shape=(64, 64, 3))  # Example shape for first image\n",
    "input_2 = Input(shape=(64, 64, 3))  # Example shape for second image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First input image processing\n",
    "x1 = Conv2D(32, (3, 3), activation='relu')(input_1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "# Second input image processing\n",
    "x2 = Conv2D(32, (3, 3), activation='relu')(input_2)\n",
    "x2 = Flatten()(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = concatenate([x1, x2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(64, activation='relu')(merged)\n",
    "output = Dense(1, activation='sigmoid')(x)  # Example output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[input_1, input_2], outputs=output)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">123008</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">123008</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">246016</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15,745,088</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m,    │        \u001b[38;5;34m896\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m,    │        \u001b[38;5;34m896\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m123008\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m123008\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m246016\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │ \u001b[38;5;34m15,745,088\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,746,945</span> (60.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,746,945\u001b[0m (60.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,746,945</span> (60.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,746,945\u001b[0m (60.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PIL import Image\n",
    "imgs=glob(\"pills_by_folder/*/*.png\")\n",
    "imgs_dict={}\n",
    "for img_path in imgs:\n",
    "    pill_type=img_path.split(\"\\\\\")[1]\n",
    "    imgs_dict[pill_type]=imgs_dict.get(pill_type,[])+[Image.open(img_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "# Assuming you have your training data ready as NumPy arrays\n",
    "# X1_train and X2_train are your two sets of images\n",
    "# y_train are the labels\n",
    "\n",
    "# Example data shape\n",
    "num_sets=1000\n",
    "X1_train = []\n",
    "X2_train = []\n",
    "y_train = []\n",
    "for i in range(num_sets):\n",
    "    type1=random.choice(list(imgs_dict.keys()))\n",
    "    type2=random.choice(list(imgs_dict.keys()))\n",
    "    im1:Image.Image=random.choice(imgs_dict[type1]).rotate(random.randint(0,360))\n",
    "    im1.thumbnail((64,64))\n",
    "    im2=random.choice(imgs_dict[type2]).rotate(random.randint(0,360))\n",
    "    im2.thumbnail((64,64))\n",
    "    X1_train.append(np.array(im1))\n",
    "    X2_train.append(np.array(im2))\n",
    "    y_train.append(float(type1==type2))\n",
    "    print(i,end=\"\\r\")\n",
    "y_train=np.array(y_train)\n",
    "X1_train=np.array(X1_train)\n",
    "X2_train=np.array(X2_train)\n",
    "\n",
    "\"\"\"\n",
    "# Data augmentation (optional)\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]]], dtype=uint8)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X1_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 263ms/step - accuracy: 0.7794 - loss: 0.6427 - val_accuracy: 0.7500 - val_loss: 0.6450\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 231ms/step - accuracy: 0.7449 - loss: 0.6450 - val_accuracy: 0.7500 - val_loss: 0.6407\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 245ms/step - accuracy: 0.7770 - loss: 0.6330 - val_accuracy: 0.7500 - val_loss: 0.6363\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 236ms/step - accuracy: 0.7802 - loss: 0.6272 - val_accuracy: 0.7500 - val_loss: 0.6321\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 239ms/step - accuracy: 0.7680 - loss: 0.6260 - val_accuracy: 0.7500 - val_loss: 0.6284\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 218ms/step - accuracy: 0.7565 - loss: 0.6255 - val_accuracy: 0.7500 - val_loss: 0.6249\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 223ms/step - accuracy: 0.7723 - loss: 0.6165 - val_accuracy: 0.7500 - val_loss: 0.6212\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 215ms/step - accuracy: 0.7918 - loss: 0.6057 - val_accuracy: 0.7500 - val_loss: 0.6179\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - accuracy: 0.7878 - loss: 0.6031 - val_accuracy: 0.7500 - val_loss: 0.6148\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 221ms/step - accuracy: 0.7706 - loss: 0.6059 - val_accuracy: 0.7500 - val_loss: 0.6118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25d0e093410>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit([X1_train, X2_train], y_train, \n",
    "          epochs=10, \n",
    "          batch_size=32, \n",
    "          validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "[0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665, 0.3993665] 0.0\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict([X1_train[0:], X2_train[0:]])\n",
    "print([prediction for prediction,*_ in predictions],y_train[0])\n",
    "Image.fromarray(X1_train[0]).save(\"1.png\")\n",
    "Image.fromarray(X2_train[0]).save(\"2.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
